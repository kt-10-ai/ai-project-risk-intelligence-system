# Meridian â€” AI Project Risk Intelligence System

> **Real-time, multi-agent risk scoring, simulation, and mitigation for software projects.**

Meridian tracks 15 signals across 5 risk dimensions, runs deterministic scoring plus 10,000-run Monte Carlo simulations, and surfaces actionable mitigation plans â€” all through a live React dashboard backed by a FastAPI + Python engine.

---

## Table of Contents

1. [Quick Start](#quick-start)
2. [Architecture Overview](#architecture-overview)
3. [Risk Model Explained](#risk-model-explained)
4. [API Reference](#api-reference)
5. [Project Structure](#project-structure)
6. [Running Individual Modules](#running-individual-modules)
7. [Configuration & Data](#configuration--data)
8. [Pages & What They Do](#pages--what-they-do)
9. [Troubleshooting](#troubleshooting)

---

## Quick Start

### 1. Backend

```bash
# From the MAIN/ directory
python -m venv .venv
source .venv/bin/activate          # Windows: .venv\Scripts\activate
pip install fastapi uvicorn

# Start the server (always run from MAIN/ with PYTHONPATH set)
PYTHONPATH=. python -m uvicorn api.main:app --reload --port 8000
```

Verify it's running:
```bash
curl http://localhost:8000/api/health
# â†’ {"status":"ok","system":"Meridian"}
```

### 2. Frontend

```bash
cd react-app
npm install
npm run dev
# â†’ http://localhost:5173
```

The frontend proxies `/api/*` to `localhost:8000` automatically (configured in `vite.config.ts`).

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    React Frontend (Vite)                 â”‚
â”‚  Dashboard Â· Simulation Â· Dependency Â· Workload Â· ...   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ REST  /api/*
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI  (api/main.py + api/routes.py)      â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                                      â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  supervisor_agent â”‚            â”‚   core/                 â”‚
â”‚  orchestrates 5   â”‚            â”‚   signal_extractor.py   â”‚
â”‚  specialist agentsâ”‚            â”‚   risk_formula.py       â”‚
â”‚                   â”‚            â”‚   whatif_engine.py      â”‚
â”‚  dependency_agent â”‚            â”‚   monte_carlo.py        â”‚
â”‚  workload_agent   â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  scope_agent      â”‚
â”‚  delay_agent      â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  comms_agent      â”‚            â”‚  data/                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  unified_project_state  â”‚
                                 â”‚  .json  â† source of     â”‚
                                 â”‚  truth for all signals  â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Request flow for `/api/analysis`:**

1. Load `unified_project_state.json`
2. `signal_extractor.py` â†’ compute 15 normalised signals (0â€“1)
3. `risk_formula.py` â†’ weighted aggregation â†’ deterministic score (0â€“100)
4. 5 agents run in parallel (ThreadPoolExecutor) â†’ each returns evidence + reasoning
5. `monte_carlo.py` â†’ 10,000 simulations with Gaussian noise on each signal
6. JSON response returned to frontend

---

## Risk Model Explained

### Signals (15 total, all normalised 0â€“1)

| Dimension | Weight | Signals |
|-----------|--------|---------|
| **Dependency** | 30% | `blocked_task_ratio`, `critical_path_depth`, `dependency_centrality_max` |
| **Delay** | 25% | `overdue_task_ratio`, `stale_task_ratio`, `avg_pr_age_days` |
| **Workload** | 20% | `overloaded_dev_ratio`, `task_concentration_index`, `unassigned_task_ratio` |
| **Scope** | 15% | `mid_sprint_task_additions`, `scope_growth_rate`, `out_of_scope_pr_count` |
| **Comms** | 10% | `silent_dev_ratio`, `unanswered_thread_ratio`, `escalation_keyword_count` |

### Interaction Penalties (up to +9 pts)

Two compound conditions are checked **after** the base score:

| Condition | Penalty | Meaning |
|-----------|---------|---------|
| `critical_path_depth > 0.70` **AND** `overloaded_dev_ratio > 0.60` | +5 pts | Cascading failure risk |
| `overdue_task_ratio > 0.70` **AND** `silent_dev_ratio > 0.50` | +4 pts | Unresolved stall pattern |

### Risk Levels

| Score | Level |
|-------|-------|
| < 40 | ðŸŸ¢ LOW |
| 40â€“59 | ðŸŸ¡ MODERATE |
| 60â€“74 | ðŸŸ  HIGH |
| â‰¥ 75 | ðŸ”´ CRITICAL |

### Monte Carlo Simulation

`core/monte_carlo.py` adds **uncertainty modelling** on top of the deterministic score. Each of the 10,000 runs samples every signal from a Gaussian distribution:

- **Low-uncertainty signals** (overdue ratio, PR age, stale ratio): Ïƒ = 0.04
- **High-uncertainty signals** (comms: silent devs, unanswered threads, escalations): Ïƒ = 0.12
- **Everything else**: Ïƒ = 0.08

The output is a full probability distribution: P(CRITICAL), P5/P95 range, 95% confidence interval, and a plain-English verdict.

---

## API Reference

All endpoints are served at `http://localhost:8000`.

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/health` | Health check |
| `GET` | `/api/analysis` | Full risk analysis â€” score, agents, signals, Monte Carlo |
| `POST` | `/api/simulate` | What-if simulation with a single mutation |
| `GET` | `/api/monte-carlo` | Standalone Monte Carlo run (10,000 simulations) |
| `WS` | `/ws/analysis` | WebSocket stream: live per-agent events |

### POST `/api/simulate` â€” Mutation types

```json
{ "type": "add_developers", "count": 2 }
{ "type": "extend_deadline", "days": 14 }
{ "type": "remove_scope",    "task_count": 5 }
{ "type": "close_prs",       "pr_count": 3 }
```

Response includes `baseline`, `simulated`, and `delta` scores so you can see exactly how much each intervention moves the needle.

### GET `/api/monte-carlo` â€” Example response

```json
{
  "n_simulations": 10000,
  "mean_score": 76.98,
  "std_deviation": 3.52,
  "percentile_5": 70.6,
  "percentile_95": 81.7,
  "confidence_interval": { "lower": 70.1, "upper": 83.9 },
  "risk_level_distribution": { "LOW": 0.0, "MODERATE": 0.0, "HIGH": 27.4, "CRITICAL": 72.6 },
  "probability_critical": 0.726,
  "verdict": "LIKELY CRITICAL: 73% probability of CRITICAL status."
}
```

---

## Project Structure

```
MAIN/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py          # FastAPI app, CORS, mounts router + WebSocket
â”‚   â”œâ”€â”€ routes.py        # All REST endpoints
â”‚   â”œâ”€â”€ schemas.py       # Pydantic request/response models
â”‚   â””â”€â”€ websocket.py     # /ws/analysis streaming endpoint
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ supervisor_agent.py     # Orchestrates all agents, returns final output
â”‚   â”œâ”€â”€ dependency_agent.py     # Analyses blocked tasks, critical path
â”‚   â”œâ”€â”€ workload_agent.py       # Analyses dev overload, task concentration
â”‚   â”œâ”€â”€ scope_agent.py          # Detects scope creep, mid-sprint additions
â”‚   â”œâ”€â”€ delay_agent.py          # Stale PRs, overdue tasks, PR age
â”‚   â”œâ”€â”€ comms_agent.py          # Silent devs, unanswered threads, keywords
â”‚   â””â”€â”€ base_agent.py           # Shared agent utilities
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ signal_extractor.py     # Raw data â†’ 15 normalised signals
â”‚   â”œâ”€â”€ risk_formula.py         # Signals â†’ weighted score + penalties
â”‚   â”œâ”€â”€ whatif_engine.py        # Mutation engine for what-if scenarios
â”‚   â””â”€â”€ monte_carlo.py          # 10,000-run probabilistic risk simulation
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ unified_project_state.json   # The project data Meridian reads from
â”‚
â”œâ”€â”€ react-app/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ pages/           # One file per page (Dashboard, Simulation, ...)
â”‚       â”œâ”€â”€ components/      # Reusable UI (Layout, RiskBadge, MonteCarloPanel, ...)
â”‚       â”œâ”€â”€ api/
â”‚       â”‚   â””â”€â”€ meridianApi.ts   # All API calls + TypeScript types
â”‚       â””â”€â”€ context/
â”‚           â”œâ”€â”€ AuthContext.tsx  # Login/auth state
â”‚           â””â”€â”€ RiskContext.tsx  # Global risk analysis state
â”‚
â”œâ”€â”€ config.py         # Shared config (DATA_PATH, etc.)
â””â”€â”€ .env              # Environment variables
```

---

## Running Individual Modules

You can run each core module directly to test it in isolation. **Always run from `MAIN/` with `PYTHONPATH=.`**

```bash
# Full risk score (deterministic)
PYTHONPATH=. python core/risk_formula.py

# Signal extraction only
PYTHONPATH=. python core/signal_extractor.py

# What-if simulation (4 built-in scenarios)
PYTHONPATH=. python core/whatif_engine.py

# Monte Carlo â€” 10,000 simulations
PYTHONPATH=. python core/monte_carlo.py

# Full supervisor agent run
PYTHONPATH=. python agents/supervisor_agent.py
```

Each script prints a formatted breakdown to stdout â€” useful for quick debugging without starting the full server.

---

## Configuration & Data

### `data/unified_project_state.json`

This is the **single source of truth** for all risk calculations. It contains:

- `tasks[]` â€” list of all project tasks with status, assignee, blocked-by
- `pull_requests[]` â€” open PRs with age and review state
- `team[]` â€” dev workload and activity timestamps
- `communications[]` â€” thread data, escalation keywords
- `metadata` â€” sprint info, simulated timestamp

To test with different project states, swap in a different JSON file at this path, then call `/api/analysis`.

### `.env`

Currently used for auth-related settings. The backend data path is hardcoded relative to `MAIN/` and does not need an env variable.

---

## Pages & What They Do

| Page | Route | Purpose |
|------|-------|---------|
| **Dashboard** | `/` | Live composite score gauge, agent matrix, what-if simulator cards, mitigation priorities |
| **Simulation Engine** | `/simulation` | Slider-based what-if scenarios + Monte Carlo panel (10,000 runs on demand) |
| **Dependency** | `/dependency` | Deep-dive into blocked tasks, critical path, dependency graph |
| **Workload** | `/workload` | Dev overload, task concentration, unassigned task analysis |
| **Scope** | `/scope` | Mid-sprint additions, scope growth rate, orphan PRs |
| **Delay** | `/delay` | Overdue tasks, stale PRs, avg PR age breakdown |
| **Comms** | `/comms` | Silent developers, unanswered threads, escalation keyword frequency |
| **Report** | `/report` | Exportable full-project risk report |

---

## Troubleshooting

**`ModuleNotFoundError: No module named 'core'`**
â†’ Always run the backend or scripts with `PYTHONPATH=.` from the `MAIN/` directory.

**Frontend shows "Backend Offline"**
â†’ Check that uvicorn is running on port 8000 (`curl http://localhost:8000/api/health`). The Vite dev server proxies `/api` to `localhost:8000`.

**`/api/analysis` returns 500**
â†’ Check `uvicorn_log.txt` or the terminal for the Python traceback. Most common cause: `unified_project_state.json` is missing or malformed.

**Monte Carlo always shows 0% CRITICAL**
â†’ The signal scores in `unified_project_state.json` are likely all zero. Run `PYTHONPATH=. python core/signal_extractor.py` to verify signals are being extracted correctly.

**How do I add a new signal?**
1. Add extraction logic in `core/signal_extractor.py`
2. Add it to the appropriate agent mean in `core/risk_formula.py` and `core/monte_carlo.py`
3. Add a display entry in `react-app/src/api/meridianApi.ts` â†’ `SIGNAL_META`
